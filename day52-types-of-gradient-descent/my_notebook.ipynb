{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2dcac520-b97e-495d-872b-ca6f6e0009c4",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7773c118-0654-4281-8883-054bfb133398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b27861-fa6d-4adb-acbd-5be9f9b22bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDRegressor:\n",
    "\n",
    "    def __init__(self, lr, epochs):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        # initializing the coefficients\n",
    "        self.intercept_ = 0                       # B0 (usual convention is to set it 0)\n",
    "        self.coef_ = np.ones(X_train.shape[1])    # array of length = number of features (for each B1 - Bm) (usual convention is to set 1)\n",
    "\n",
    "        # updating the values\n",
    "        for epoch in range(self.epochs):\n",
    "            y_pred = self.intercept_ + np.dot(X_train, self.coef_)                       # y_pred = B0 + B1X1 + B2X2 + ... BmXm \n",
    "\n",
    "            # updating B0\n",
    "            gradient_intercept = -2 * np.mean(y_train - y_pred)                          # summation and 1/n is handled by mean\n",
    "            self.intercept_ = self.intercept_ - (self.lr * gradient_intercept)\n",
    "            \n",
    "            # updating B1 - Bm\n",
    "            gradient_coef = -2 * np.dot(y_train - y_pred, X_train) / X_train.shape[0]    # summation is handled by the dot product \n",
    "                                                                                         # this is beacause we are calculating all the coeffs together\n",
    "                                                                                         # and so took the entire X and not just Xim thus we could do dot product\n",
    "            self.coef_ = self.coef_ - (self.lr * gradient_coef)\n",
    "\n",
    "        print(self.coef_, self.intercept_)\n",
    "        \n",
    "    def predict(self, X_test):\n",
    "        return self.intercept_ + np.dot(X_test, self.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f75a326f-cf91-440d-8472-42a8842c8f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((442, 10), (442,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X. shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fe8c1ae-28b3-4dc3-ba47-9fcc6dea853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27655823-949a-4bee-ba3a-b59b391d5529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  41.84393613 -203.16516259  509.57171213  325.0324614   -71.03313832\n",
      " -119.2751067  -215.83226818  144.71956871  376.4816763   111.9934672 ] 151.37285989314483\n"
     ]
    }
   ],
   "source": [
    "gdr = GDRegressor(lr=0.1, epochs=5000)\n",
    "gdr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "227ddaff-f74c-49c2-943f-dba2ddd5e591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45888362659344617"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_gdr = gdr.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ff95992f-8ab4-4e1e-bccb-7cc26adc66cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45888362659344617"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred_reg = reg.predict(X_test)\n",
    "\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4927ad04-e72b-4423-b57b-78d2f70d4209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(151.34560453985995),\n",
       " array([  37.90402135, -241.96436231,  542.42875852,  347.70384391,\n",
       "        -931.48884588,  518.06227698,  163.41998299,  275.31790158,\n",
       "         736.1988589 ,   48.67065743]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_, reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad15eee-0333-47fd-a34a-cca27bb7c6f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
