{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62a62cfc-1273-4c23-b642-c0ff98822f01",
   "metadata": {},
   "source": [
    "# Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8c72579-a1cd-44c3-b03d-167aab85a686",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e72ba340-1b03-4e93-87a6-4ddaefeb706d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBGDRegressor:\n",
    "\n",
    "    def __init__(self, lr=0.01, epochs=1000, batch_size=32):\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.intercept_ = 0\n",
    "        self.coef_ = np.ones(X_train.shape[1])\n",
    "        \n",
    "        for epoch in range(self.epochs):\n",
    "            for i in range(X_train.shape[0] // self.batch_size):                                          # no. of updates per epoch = total_samples / batch_size\n",
    "                random_idx = np.random.choice(range(X_train.shape[0]), self.batch_size, replace=False)    # random index of batch_size no. of rows\n",
    "                y_pred = self.intercept_ + (X_train[random_idx] @ self.coef_)                             # y_pred for batch_size no. of rows \n",
    "\n",
    "                intercept_gradient = -2 * np.mean(y_train[random_idx] - y_pred)\n",
    "                coef_gradient = -2 * ((y_train[random_idx] - y_pred) @ X_train[random_idx])\n",
    "\n",
    "                self.intercept_ = self.intercept_ - (self.lr * intercept_gradient)\n",
    "                self.coef_ = self.coef_ - (self.lr * coef_gradient)\n",
    "\n",
    "        print(self.intercept_, self.coef_)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        return self.intercept_ + (X_test @ self.coef_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "5122a216-17a3-40f3-9b2f-5c8e956c3d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_diabetes(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c84aac75-7d45-45ef-b466-c734b0922cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "c24dae87-4e26-4d93-9861-5ae48135402e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "154.671496351471 [  29.74437507 -227.57692211  546.46744266  335.44481373 -166.45883757\n",
      "  -69.85467767 -162.16750236  148.26573923  459.13398203   64.23500322]\n"
     ]
    }
   ],
   "source": [
    "mbgd = MBGDRegressor(lr=0.1, epochs=100, batch_size=32)\n",
    "mbgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "71a5cff9-49d3-40d5-b8e2-5251713e9f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.46562702695533864"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = mbgd.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bf3db6-d839-4510-ac70-69d1b30da7e7",
   "metadata": {},
   "source": [
    "## For sklearn there is no Mini Batch GD so we have to do a workaround"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6b560b08-43a4-44c9-8400-4412997a0625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGDRegressor(learning_rate='adaptive', eta0=0.1)    # no need for max iter as we are gonna use partial fit\n",
    "batch_size = 10\n",
    "\n",
    "# total there will be 600 updates, instead of dividing into epochs and all\n",
    "# each update will look at 10 samples \n",
    "for i in range(600):\n",
    "    random_idx = np.random.choice(range(X_train.shape[0]), batch_size, replace=False)    # random index of batch_size no. of samples\n",
    "    sgd.partial_fit(X_train[random_idx], y_train[random_idx])                            # partial fit method only does one epoch (one update) of GD for n samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0204efae-7484-4dc6-99fe-012e47c2d432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([140.75462224]),\n",
       " array([  57.1443836 , -139.29114359,  439.49965371,  281.93198536,\n",
       "         -35.99113592,  -87.31349628, -200.92641101,  139.48387181,\n",
       "         325.30172143,  124.56389459]))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.intercept_, sgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05aeb60a-1701-44ca-9d62-e602433f11b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4621446214887822"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = sgd.predict(X_test)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f14f285f-235a-4eac-9ff4-4f9d9f3575ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-13.91687411]),\n",
       " array([  27.40000853,   88.28577852, -106.96778894,  -53.51282837,\n",
       "         130.46770165,  -17.45881861,  -38.75890865,   -8.78186743,\n",
       "        -133.8322606 ,   60.32889136]))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.intercept_ - mbgd.intercept_, sgd.coef_ - mbgd.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef747f11-dd1d-4682-92c8-b2458b1bef96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
